{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea505a5f",
   "metadata": {},
   "source": [
    "Q1:\n",
    "\n",
    "1.Simple vs. Multiple Linear Regression:\n",
    "\n",
    "  Simple Linear Regression (SLR) uses one predictor to estimate an outcome.\n",
    "  Multiple Linear Regression (MLR) uses multiple predictors, allowing it to capture more complexity.\n",
    "  Benefit: MLR provides more accurate predictions by considering multiple factors.\n",
    "\n",
    "2.Continuous vs. Indicator Variable in SLR:\n",
    "\n",
    "  Continuous Variable: Allows gradual changes in the outcome.\n",
    "  Indicator Variable: Represents categories, causing distinct shifts rather than gradual changes.\n",
    "\n",
    "3.Adding an Indicator with a Continuous Variable in MLR:\n",
    "\n",
    "  Adding an indicator lets the model create separate baselines for each category while still adjusting for the   \n",
    "  continuous variable.\n",
    "  SLR vs. MLR: SLR has a single line; MLR creates parallel lines for each group.\n",
    "\n",
    "4.Adding an Interaction Between Continuous and Indicator Variable:\n",
    "\n",
    "  An interaction term changes the slope for each category, allowing a unique effect of the continuous variable  \n",
    "  within each category.\n",
    "  Form: The lines for each group are no longer parallel, better reflecting group differences.\n",
    "\n",
    "5.MLR with Only Indicator Variables from a Categorical Variable:\n",
    "\n",
    "  For multiple categories, we create binary variables for each, except one reference category.\n",
    "  Encoding: This gives each category its baseline while avoiding overlapping variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc6686",
   "metadata": {},
   "source": [
    "Q2.\n",
    "\n",
    "1.Outcome and Predictors:\n",
    "\n",
    "  The goal is to predict sales based on TV and online advertising budgets.\n",
    "  An interaction effect may exist, where the impact of spending on one medium depends on spending on the other.\n",
    "\n",
    "2.Model Without Interaction:\n",
    "\n",
    "  Each advertising type independently affects sales. TV and online budgets have separate effects that don’t \n",
    "  influence each other.\n",
    "\n",
    "3.Model With Interaction:\n",
    "\n",
    "  This model considers how TV and online spending impact each other’s effectiveness, allowing for a combined effect \n",
    "  that may amplify or reduce sales.\n",
    "\n",
    "4.Binary Budgets (\"High\" or \"Low\"):\n",
    "\n",
    "  With this adjustment, budgets are categorized instead of being specific dollar amounts. The interaction model \n",
    "  here shows the impact when both types are either \"high\" or \"low,\" allowing for more nuanced group-based \n",
    "  predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c7d0aa",
   "metadata": {},
   "source": [
    "Q4.\n",
    "\n",
    "1.Model Fit (17.6% variability explained): The model explains only a small part of the total variability in the outcome, meaning other factors not in the model affect the outcome significantly.\n",
    "\n",
    "2.Significant Coefficients: Despite low overall fit, many predictors have large coefficients and strong evidence against the null hypothesis, indicating they have a meaningful, statistically significant impact on the outcome individually.\n",
    "\n",
    "Reconciliation: The model's predictors are important but don't capture all factors affecting the outcome. Individual predictors can significantly impact the outcome even if the model doesn’t fully explain the overall variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932e17d",
   "metadata": {},
   "source": [
    "Q5.\n",
    "\n",
    "1.In-Sample R-squared Calculation:\n",
    "\n",
    "The in-sample R-squared is calculated as the squared correlation between the observed outcomes and their fitted values from the model. This measures how well the model explains variability in the data used to train it.\n",
    "High in-sample R-squared suggests the model fits the training data well, but it doesn’t necessarily indicate that it will perform well on new, unseen data.\n",
    "\n",
    "2.Out-of-Sample R-squared Calculation:\n",
    "\n",
    "The out-of-sample R-squared is calculated by splitting the data into training and testing sets, fitting the model on the training data, and then predicting outcomes for the test data.\n",
    "This measures how well the model’s predictions generalize to new data, which is crucial for assessing the model's real-world applicability.\n",
    "\n",
    "3.Model Generalizability and Overfitting:\n",
    "\n",
    "If the out-of-sample R-squared is significantly lower than the in-sample R-squared, the model may be overfit, meaning it captures specific patterns in the training data that don’t generalize well.\n",
    "Overfitting indicates the model performs well on training data but poorly on unseen data, compromising its predictive power.\n",
    "\n",
    "4.Purpose of Training and Testing Split:\n",
    "\n",
    "The comparison between in-sample and out-of-sample performance helps to assess if the model is generalizable or if it’s just \"memorizing\" the training data.\n",
    "A good model should have similar in-sample and out-of-sample performance, indicating it’s capturing underlying relationships rather than noise.\n",
    "\n",
    "5.Illustration of Practical Model Evaluation:\n",
    "\n",
    "This approach shows the importance of using separate training and testing sets to ensure the model’s predictions will hold up in real-world scenarios, beyond the specific dataset used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a40c08c",
   "metadata": {},
   "source": [
    "6.\n",
    "\n",
    "Design Matrix Creation: (model4_linear_form) creates new predictor variables for the design matrix (model4_spec.exog), which holds all predictors specified in the model.\n",
    "\n",
    "Multicollinearity: When predictors in the design matrix are highly correlated (multicollinear), they contain redundant information, making coefficient estimates unstable and sensitive to data changes.\n",
    "\n",
    "Impact on Generalization: Multicollinearity leads to overfitting, where the model captures noise specific to the training data, reducing \"out-of-sample\" accuracy and generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879fb7bf",
   "metadata": {},
   "source": [
    "Q7.\n",
    "\n",
    "1.From model3_fit to model4_fit:\n",
    "\n",
    "Rationale: model4_fit builds on model3_fit by introducing additional predictors or interaction terms that were not in model3_fit.\n",
    "\n",
    "Principle: By adding interactions or non-linear transformations, model4_fit aims to capture more complex relationships in the data that model3_fit may not account for.\n",
    "\n",
    "2.From model4_fit to model5_linear_form:\n",
    "\n",
    "Rationale: model5_linear_form extends model4_fit by adding further interactions, transformations, or possibly polynomial terms to better model the relationships and capture subtleties.\n",
    "\n",
    "Principle: Increasing model flexibility can help capture more variation in the data but also risks overfitting, so these extensions should be tested for improvement in generalization.\n",
    "\n",
    "3.From model5_linear_form to model6_linear_form:\n",
    "\n",
    "Rationale: model6_linear_form adds even more complexity, likely introducing higher-order interactions or more refined transformations to capture nuanced relationships.\n",
    "\n",
    "Principle: The goal is to achieve a better fit by expanding the model’s ability to represent complex dependencies, balancing complexity with predictive accuracy.\n",
    "\n",
    "4.From model6_linear_form to model7_linear_form:\n",
    "\n",
    "Rationale: model7_linear_form represents the most complex form, incorporating all relevant interactions and predictors from previous models while refining or adding final adjustments to maximize predictive power.\n",
    "\n",
    "Principle: This final extension aims to achieve the best fit for the data, potentially acting as the \"full model\" that can be pruned or adjusted based on validation results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e46f71",
   "metadata": {},
   "source": [
    "Q8.\n",
    "\n",
    "The code repeatedly splits the data, fits a model, and calculates in-sample and out-of-sample R-squared values to assess model generalizability. By varying the data splits (no fixed random seed), it captures performance variability across different samples.\n",
    "\n",
    "In-Sample vs. Out-of-Sample: In-sample R-squared shows how well the model fits the training data, while out-of-sample R-squared indicates generalizability to new data.\n",
    "\n",
    "Visualization: A scatter plot of in-sample vs. out-of-sample R-squared values reveals patterns, with points far above the y=x line suggesting overfitting.\n",
    "\n",
    "Purpose: This process checks if the model performs consistently across samples or if it overfits to specific training sets, highlighting generalizability issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d1f59",
   "metadata": {},
   "source": [
    "Q9.\n",
    "\n",
    "1.Model Complexity:\n",
    "\n",
    "model7_fit is more complex than model6_fit, containing more interactions and higher-order terms. This complexity provides higher \"in-sample\" performance but raises concerns about overfitting, as it may capture patterns unique to the training data rather than general trends.\n",
    "\n",
    "2.Interpreting \"In-Sample\" and \"Out-of-Sample\" R-squared:\n",
    "\n",
    "In-sample R-squared is measured using the data the model was trained on, while out-of-sample R-squared tests the model’s performance on unseen data, simulating future data.\n",
    "\n",
    "In this example, predictions are made on data from different \"Generations\" (e.g., predicting outcomes for Generation!=1 using data from Generation=1). This approach mimics a scenario where we use past data to make predictions about future data.\n",
    "\n",
    "3.Results and Observations:\n",
    "\n",
    "The in-sample R-squared for model7_fit is high, indicating it fits the training data well, but its out-of-sample R-squared drops significantly when predicting different generations, indicating poorer generalizability.\n",
    "\n",
    "model6_fit, being simpler, has slightly lower in-sample performance but maintains more consistent out-of-sample performance, showing it’s less prone to overfitting and better suited for making predictions on new data.\n",
    "\n",
    "4.Why Model6 May Be Preferred:\n",
    "\n",
    "Although model7_fit initially showed better predictive performance, its complexity introduces interpretability challenges and risks overfitting, which become evident when testing with sequential data.\n",
    "\n",
    "Parsimony Principle: In many cases, a simpler model (model6_fit) is preferred because it provides a balance between interpretability and generalizability, especially when differences in out-of-sample performance are minimal.\n",
    "\n",
    "5.Real-World Implication:\n",
    "\n",
    "This example highlights that the choice of training and testing splits affects generalizability evaluation. When using data sequentially (as it would be in real-time predictions), a complex model like model7_fit may perform worse than a simpler model like model6_fit, emphasizing that models with higher interpretability and consistency often outperform overly complex models on unseen data.\n",
    "\n",
    "In summary, this code and analysis show the importance of balancing model complexity with interpretability and generalizability, demonstrating that simpler models often perform more reliably on future data in real-world prediction scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459bede",
   "metadata": {},
   "source": [
    "Chat GPT Link:https://chatgpt.com/share/67365c3a-6bfc-800f-a196-b3589a167977"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
